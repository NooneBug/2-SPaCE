#define here all constants
# DEFAULT will provide base values for constants

#dataset
[DEFAULT]
LEFT_CONTEXT = left_context_tokens
MENTION = mention
RIGHT_CONTEXT = right_context_tokens
LABELS = labels
DATASET_PATH = toy_datasets/toy_simple_input
TYPE_SPACE_NUMBER = 2

[GLOVE]
WORD_EMBEDDING_PATH = resources/word_embeddings/toy_glove.txt

[MultiTypeEmbedding]
# explicit the embedding configurations through EMBEDDING_CONFIGS
# use config names separated by one single space
EMBEDDING_CONFIGS = NICKEL TYPE2VEC
PADDING_INDEX = -1

[NICKEL]

NAME = nickel_hyperbolic
PATH = resources/type_embeddings/toy_nickel.pth
EMBEDDING_CLASS_NAME = NickelEmbedding

[TYPE2VEC]

NAME = type2vec
PATH = resources/type_embeddings/toy_t2v
EMBEDDING_CLASS_NAME = Type2VecEmbedding

[2-SPACE MODULES CONFIGS]
WORD_MANIPULATION_MODULE = SHIMAOKA
DEEP_NETWORK = COMMON
; PROJECTORS = HYPERBOLIC_PROJECTOR COSINE_PROJECTOR

[SHIMAOKA]
CLASS = ShimaokaModel
DATALOADER_CLASS = ShimaokaDataLoader
# OUTPUT_SIZE = context_rnn_size * 2 + emb_size + char_emb_size 
OUTPUT_SIZE = 750
PADDING_INDEX = -1
CHAR_PAD = <pad>
context_rnn_size = 200
emb_size = 300
char_emb_size = 50
mention_dropout_size = 0.5
positional_emb_size = 25
context_dropout = 0.2
mention_length = 5
max_char_in_mention = 25

[COMMON]
CLASS = CommonNetwork
INPUT_SIZE = 750
layers = 512 512
dropout_prob = 0.2

[HYPERBOLIC_PROJECTOR]
CLASS = HyperbolicProjector

[COSINE_PROJECTOR]
CLASS = CosineProjector

[TRAINING_PARAMETERS]
train_batch_size = 1024
shuffle = False
val_batch_size = 1024